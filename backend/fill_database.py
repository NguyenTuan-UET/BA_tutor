import os
from dotenv import load_dotenv
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import (
    DirectoryLoader,
    PyPDFLoader,
    TextLoader,
)

# Load environment
load_dotenv(os.path.join(os.path.dirname(__file__), "../.env"))
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
DATA_DIR = os.path.join(BASE_DIR, "core", "data")
CHROMA_PATH = os.path.join(BASE_DIR, "chroma_db")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL")

# Khá»Ÿi táº¡o embedding + Chroma client
embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name=EMBEDDING_MODEL
)

chroma_client = chromadb.PersistentClient(
    path=CHROMA_PATH, settings=Settings(allow_reset=True)
)

# XÃ³a vÃ  táº¡o láº¡i collection
if "knowledge_base" in [c.name for c in chroma_client.list_collections()]:
    chroma_client.delete_collection("knowledge_base")

collection = chroma_client.get_or_create_collection(
    name="knowledge_base", embedding_function=embedding_func
)

# Load tÃ i liá»‡u PDF vÃ  TXT
pdf_loader = DirectoryLoader(DATA_DIR, glob="*.pdf", loader_cls=PyPDFLoader)
txt_loader = DirectoryLoader(
    DATA_DIR, glob="*.txt", loader_cls=lambda path: TextLoader(path, encoding="utf-8")
)

documents = pdf_loader.load() + txt_loader.load()
print(f"ğŸ“„ Sá»‘ tÃ i liá»‡u Ä‘á»c Ä‘Æ°á»£c: {len(documents)}")

# Chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n nhá» (chunk) Ä‘á»ƒ xá»­ lÃ½ embedding hiá»‡u quáº£.
# - chunk_size=500: má»—i Ä‘oáº¡n tá»‘i Ä‘a 500 kÃ½ tá»±, giÃºp giáº£m Ä‘á»™ dÃ i vÄƒn báº£n Ä‘áº§u vÃ o model.
# - chunk_overlap=50: má»—i Ä‘oáº¡n sáº½ chá»“ng 50 kÃ½ tá»± vá»›i Ä‘oáº¡n trÆ°á»›c Ä‘Ã³, giá»¯ ngá»¯ cáº£nh liá»n máº¡ch.
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

# ÄÆ°a vÃ o Chroma
for i, chunk in enumerate(chunks):
    collection.add(
        documents=[chunk.page_content], metadatas=[chunk.metadata], ids=[f"chunk-{i}"]
    )

print(f"âœ… ÄÃ£ náº¡p {len(chunks)} chunk vÃ o ChromaDB.")
